import logging
import time
import shutil
from pathlib import Path

from loader import load_datasets
from cleaner import clean_data
from analyzer import analyze_and_score
from generator import create_new_titles
from stats import genre_stats, rating_stats

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    datefmt="%H:%M:%S"
)

REQUIRED_FILES = [
    Path("data/raw/netflix_titles.csv"),
    Path("data/raw/disney_plus_titles.csv"),
    Path("data/raw/amazon_prime_titles.csv"),
]


def check_required_files() -> bool:
    missing = [str(f) for f in REQUIRED_FILES if not f.exists()]

    if missing:
        logging.error("‚ùå Arquivos obrigat√≥rios n√£o encontrados em 'data/raw/':")
        for f in missing:
            logging.error(f"   - {f}")
        logging.error("Finalize o programa, coloque os CSVs na pasta correta e tente novamente.")
        return False

    logging.info("üìÇ Todos os arquivos obrigat√≥rios foram encontrados em 'data/raw/'.")
    return True


def clean_previous_outputs():
    for folder in ["data/processed", "data/outputs"]:
        path = Path(folder)
        if path.exists():
            shutil.rmtree(path, ignore_errors=True)
        path.mkdir(parents=True, exist_ok=True)

    logging.info("üßπ Pastas 'data/processed/' e 'data/outputs/' foram limpas e recriadas.")


def main():
    start_time = time.time()

    try:
        logging.info("üöÄ Iniciando pipeline de an√°lise de streaming data mining...")

        if not check_required_files():
            return

        clean_previous_outputs()

        logging.info("Carregando datasets brutos...")
        datasets_raw = load_datasets()
        logging.info(f"Datasets carregados: {', '.join(datasets_raw.keys())}")

        logging.info("Limpando e padronizando colunas...")
        datasets_clean = clean_data(datasets_raw)
        logging.info("‚úÖ Limpeza conclu√≠da. Arquivos salvos em 'data/processed/'.")

        logging.info("Gerando estat√≠sticas de g√™neros por plataforma...")
        genre_df = genre_stats(datasets_clean)
        logging.info(
            f"‚úÖ Estat√≠sticas de g√™neros salvas em 'data/outputs/genre_stats.csv' "
            f"({len(genre_df)} linhas)."
        )

        logging.info("Gerando estat√≠sticas de ratings por plataforma...")
        rating_df = rating_stats(datasets_clean)
        logging.info(
            f"‚úÖ Estat√≠sticas de ratings salvas em 'data/outputs/rating_stats.csv' "
            f"({len(rating_df)} linhas)."
        )

        logging.info("Calculando coluna de sucesso baseada na rec√™ncia...")
        combined_scores = analyze_and_score(datasets_clean)
        logging.info(
            f"‚úÖ Coluna 'sucesso' gerada com {len(combined_scores)} registros combinados "
            f"(arquivo em 'data/outputs/success_scores.csv')."
        )

        logging.info("Gerando novos filmes e s√©ries para cada plataforma...")
        novos_titulos = create_new_titles()
        logging.info(
            f"üé¨ {len(novos_titulos)} novos t√≠tulos criados e salvos em "
            f"'data/outputs/new_titles.csv'."
        )

        elapsed = time.time() - start_time
        logging.info(f"‚è±Ô∏è Pipeline conclu√≠da com sucesso em {elapsed:.2f} segundos.")

    except Exception as e:
        logging.error(f"‚ùå Erro durante a execu√ß√£o: {e}", exc_info=True)


if __name__ == "__main__":
    main()
